Starting job 1402908
Working directory: /home/chandru/binp37/scripts/slurm
Python version: Python 3.9.21
Available memory: 236Gi
Loading data from: results/metasub/tax_metasub_data.csv
Data loaded successfully. Shape: (4070, 6762)
Dataset memory usage: 0.21 GB
Available memory: 235.76 GB
Using 12 CPUs with ~15.72 GB per worker
Calculating correlation matrix...
Computing correlation matrix (this may take a while)...
Correlated features removed: 3064

Starting RFE with subsets of features: [200, 300, 400, 500, 1000, 1500, 2000]
Total iterations: 35
Storing data in Ray object store...

Best params: {'rfe__n_features_to_select': 300}
Best accuracy: 0.822359
Mean accuracy for all tested feature subsets:
   n_features  accuracy
0         200  0.815479
1         300  0.822359
2         400  0.813022
3         500  0.814005
4        1000  0.802703
5        1500  0.796314
6        2000  0.786241
Total time taken: 1912.72 seconds
Normalized path: results/metasub/metasub_tax_train_test.csv
Valid directory found. Using 'metasub_tax_train_test.csv' as the output file.
Saving results to: results/metasub/metasub_tax_train_test.csv
Results saved successfully!
Job completed successfully
Cleaning up Ray temporary files...
