\documentclass{article}
\usepackage{geometry}
\geometry{margin=1in}
\usepackage{titlesec}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{fancyhdr}
\usepackage{enumitem}
\usepackage{booktabs}

% Header and Footer
\pagestyle{fancy}
\fancyhf{}
\rhead{\textbf{Bioinformatics Research Log}}
\rfoot{Page \thepage}

% Title format
\titleformat{\section}{\Large\bfseries}{}{0pt}{}

\title{\textbf{Bioinformatics Research Project Log}}
\author{Chandrashekar CR \\ Supervisor: Dr. Eran Elhaik \\ Lund University}
\date{April 10, 2025}

\begin{document}

\maketitle
\tableofcontents
\newpage

% March 31, 2025
\section{March 31, 2025}

\subsection*{Tasks for the Day}
\begin{itemize}
    \item Understood the mGPS algorithm from the R code and implemented the preprocessing steps.
    \item Set up the working environment and installed all required libraries.
    \item Began tracking the project.
\end{itemize}

\subsection*{Notes and Observations}
\begin{itemize}
    \item Utilizing the \texttt{ai\_env} environment from previous projects and accessing resources on the bioinformatics server.
    \item Initial challenges in understanding the R code are anticipated to decrease with further engagement.
\end{itemize}

% April 1, 2025
\section{April 1, 2025}

\subsection*{Tasks for the Day}
\begin{itemize}
    \item Understood and implemented Recursive Feature Elimination followed by the XGBoost machine learning algorithm with the correct hierarchical steps.
    \item Initialized Git for version control and pushed code to GitHub.
    \item Gained a deeper understanding of cross-validation principles.
\end{itemize}

\subsection*{Notes and Observations}
\begin{itemize}
    \item Achieved a general understanding of the workflow and added comments to the MetaSUB preprocessing script in R.
    \item Acquired knowledge regarding the importance of cross-validation, although implementation is pending.
\end{itemize}

% April 2, 2025
\section{April 2, 2025}

\subsection*{Tasks for the Day}
\begin{itemize}
    \item Acquired information from Vignesh regarding access to the LUNARC server.
    \item Determined that reimplementing the exact XGBoost model is unnecessary; the focus is on understanding the input data preprocessing.
\end{itemize}

\subsection*{Notes and Observations}
\begin{itemize}
    \item Git repository initialized for the project, tracking all files except data and research papers.
    \item The \texttt{metasub\_global\_git.csv} file contains the Geographically Informative Taxa (GITs) required for the XGBoost model.
    \item The primary objective is to comprehend the preprocessing of input data for XGBoost.
    \item Key questions identified: What is the shape of the input data? What are the prediction targets?
\end{itemize}

% April 3, 2025
\section{April 3, 2025}

\subsection*{Tasks for the Day}
\begin{itemize}
    \item Implemented basic neural network architectures in PyTorch. Hyperparameter tuning indicates that 200 GITs are sufficient for accurate predictions, despite the dataset containing \( n \) data points.
    \item Integrated Ray parallel processing to optimize hyperparameters, aiming to reduce the estimated 4-5 hour search time.
    \item Preprocessed data into numerical format by converting categorical variables (continents and cities) using one-hot encoding.
    \item Deferred the implementation of stratified K-fold cross-validation for later.
\end{itemize}

\subsection*{Notes and Observations}
\begin{itemize}
    \item Successfully logged into the LUNARC server's login node, but GPU access and utilization for neural network training require further investigation.
    \item Authentication and login to LUNARC are complete; however, assistance is needed to understand:
    \begin{itemize}
        \item The location of allocated storage.
        \item The process of submitting jobs using SBATCH.
        \item The fundamentals of working on High-Performance Computing (HPC).
    \end{itemize}
    \item Following Recursive Feature Elimination (RFE), the final dataset has a shape of \(4070 \times 204\), with 200 features and 4 target variables.
    \item Each data point comprises 200 features (GITs) representing the relative sequence abundance (RSA) of microorganisms. The 4 target variables are continent, city, latitude, and longitude.
    \item The dataset includes samples from 40 unique cities across 7 continents.
    \item Categorical variables (continent and city) were encoded using \texttt{sklearn}'s \texttt{LabelEncoder}, while latitude and longitude were standardized using \texttt{StandardScaler}.
    \item Initial consideration of stratified cross-validation was temporarily replaced with \texttt{train\_test\_split} for initial model development. Stratified cross-validation will be revisited for enhanced model performance.
\end{itemize}

\subsubsection*{Neural Network Architecture}
\begin{itemize}
    \item The initial model is a simple feedforward neural network, inspired by the hierarchical structure of the previous XGBoost study.
    \item The first version includes an input layer (200 nodes), two hidden layers (400 nodes each), a smaller hidden layer (2 nodes), and an output layer (7 nodes for the 7 continents).
    \item The plan is to initially train this model to predict the continent. Subsequently, the predicted continent probabilities will be concatenated with the original 200 features as input for a second neural network (similar architecture) to predict the city.
    \item The optimal handling of latitude and longitude values within the neural network remains an open question.
    \item Long training times due to CPU-based computation on the bioinformatics server are a significant challenge. GPU access on the LUNARC cluster is required.
\end{itemize}

% April 4, 2025
\section{April 4, 2025}

\subsection*{Tasks for the Day}
\begin{itemize}
    \item Finalized the presentation for the weekly lab meeting.
    \item Focused on obtaining GPU access and understanding HPC architecture.
    \item Initiated preprocessing for marine and soil datasets, aiming for modular script design applicable to all datasets.
\end{itemize}

\subsection*{Notes and Observations}
Explored various neural network implementations and gained initial understanding of HPC principles.

% April 7, 2025
\section{April 7, 2025}

\subsection*{Tasks for the Day}
\begin{itemize}
    \item Developed a functional neural network to predict all target variables (continent, city, latitude, and longitude).
    \item Completed preprocessing steps for marine and soil datasets.
    \item Began modularizing code for efficient execution on the HPC.
\end{itemize}

\subsection*{Notes and Observations}
\begin{itemize}
    \item Developed a working script for MetaSUB data processing, with pending error handling and file format validation.
    \item Created a working script to extract relevant features using Recursive Feature Elimination with a Random Forest base model.
    \item Initiated work on the HPC, understanding basic operations and starting to modularize scripts for GPU compute nodes.
\end{itemize}

% April 8, 2025
\section{April 8, 2025}
\subsection*{Notes and Observations}
\begin{itemize}
    \item Started building multiple neural network models.
    \item Began learning batch scripting using SLURM.
\end{itemize}

% April 10, 2025
\section{April 10, 2025}
\subsection*{Notes and Observations}
\begin{itemize}
    \item Exploring alternative scaling methods for latitude and longitude, including conversion to radians and trigonometric transformation into a two-dimensional space.
\end{itemize}

% April 11, 2025
\section{April 11, 2025}
\subsection*{Tasks for the day}
\begin{itemize}
    \item These are some of my thoughts. The currrent approach is always making a new neural network model from scratch for each dataset. A final model should be made 
    that utilizes all the iterations done and must work for all type of datasets regardless of the layers of predictions. 
    \item For example, the MetaSUB dataset contains informaiton on the continent, city, latitude and longitude. Whereas the marine dataset contain information only the sea, latitude and longitude.
    There should be a way that can handle these cases instead of definfing a newtwork from scratch.
    \item Finish the logic for the latitude and longitude neural network model. 
    \item Compare the three models with metasub dataset on accuracy, confusion matrix, plot on world map.
\end{itemize}

% April 14, 2025
\section{April 14, 2025}

\subsection*{Notes and Observations}
\begin{itemize}
    \item \textbf{Combined Models Generally Outperform Separate Models:} Models 2 (nn\_model\_combined.py) and 4 (nn\_combined\_model\_lat\_long.py), which employ combined or hierarchical architectures, tend to show better performance, particularly on the latitude and longitude/XYZ prediction tasks, compared to Model 1 (nn\_model.py) and Model 3 (nn\_model\_lat\_long.py) which use separate networks.
    
    \item \textbf{XYZ Coordinate Transformation Seems Beneficial:} Models 3 and 4, which incorporate the transformation of latitude and longitude into XYZ coordinates, demonstrate significantly lower Mean Absolute Errors for these predictions compared to Model 1, which predicts latitude and longitude directly.
    
    \item \textbf{Trade-offs Between Classification and Regression:} There isn't one single model that dominates across all tasks. Some models show higher accuracy for continent and city prediction, while others excel in latitude and longitude prediction.
    
    \item \textbf{Overfitting:} In several instances, the training accuracy is notably higher than the test accuracy, suggesting some degree of overfitting across the models. This is a common challenge in machine learning and something to consider for future improvements.
\end{itemize}

\subsection*{Model-by-Model Comparison}
\begin{itemize}
    \item \textbf{Model 1: nn\_model.py (Right Top Corner)}
    \begin{itemize}
        \item \textbf{Continent Prediction:} Strong test accuracy (89.56\%) with balanced precision, recall, and F1-score.
        \item \textbf{Cities Prediction:} Lower test accuracy (78.75\%) compared to continent prediction.
        \item \textbf{Latitude and Longitude Prediction:} High MAEs (0.3964 and 0.3445). Maps show significant spread between predictions and true locations.
        \item \textbf{Architecture:} Uses separate networks for each task, which may limit learning of shared representations.
    \end{itemize}

    \item \textbf{Model 2: nn\_model\_combined.py (Left Bottom Corner)}
    \begin{itemize}
        \item \textbf{Continent Prediction:} Slightly lower test accuracy (88.33\%) than Model 1.
        \item \textbf{Cities Prediction:} Improved test accuracy (81.82\%) with higher precision and F1-score.
        \item \textbf{Latitude and Longitude Prediction:} Lowest MAEs (0.2230 and 0.1876). Very accurate predictions, as confirmed by maps.
        \item \textbf{Architecture:} Hierarchical structure facilitates learning between tasks.
    \end{itemize}

    \item \textbf{Model 3: nn\_model\_lat\_long.py (Right Bottom Corner)}
    \begin{itemize}
        \item \textbf{Continent Prediction:} High test accuracy (89.31\%).
        \item \textbf{Cities Prediction:} Lowest test accuracy (75.92\%) among all models.
        \item \textbf{Latitude and Longitude Prediction:} Very high MAEs (8.5982 and 21.2971). Severe scatter on maps.
        \item \textbf{Architecture:} Uses XYZ internally but has poor coordinate prediction, possibly due to flawed transformations or output layers.
    \end{itemize}

    \item \textbf{Model 4: nn\_combined\_model\_lat\_long.py (Left Top Corner)}
    \begin{itemize}
        \item \textbf{Continent Prediction:} Slightly lower test accuracy (87.35\%).
        \item \textbf{Cities Prediction:} Highest test accuracy (82.92\%) among all models.
        \item \textbf{Latitude and Longitude Prediction:} Low MAEs (4.5070 and 14.4377), but not as low as Model 2.
        \item \textbf{Architecture:} Combines hierarchical structure with XYZ usage, effective for cities and coordinates.
    \end{itemize}
\end{itemize}

\subsection*{Comparative Analysis and Best Model}
\begin{itemize}
    \item \textbf{Best for Coordinates:} Model 2 clearly outperforms others in latitude and longitude prediction.
    \item \textbf{Best for Cities:} Model 4 achieves the highest accuracy.
    \item \textbf{Continent Accuracy:} All models perform similarly well.
    \item \textbf{Overall Best Model:} Model 2 (nn\_model\_combined.py) is the most well-rounded, offering competitive classification accuracy and the best coordinate prediction performance.
\end{itemize}

\subsection*{Opportunities for Improvement}
\begin{itemize}
    \item \textbf{Reduce Overfitting:} Apply techniques like dropout, L1/L2 regularization, or early stopping.
    \item \textbf{Fix Model 3:} Investigate XYZ conversion and back-transformation.
    \item \textbf{Refine Hierarchical Designs:} Experiment with alternative fusion strategies or attention mechanisms.
    \item \textbf{Ensemble Strategies:} Combining predictions may improve performance across tasks.
\end{itemize}


% April 16th, 2025

\section{June 4, 2025}
Performing recursive feature selection on the tax\_metasub\_data.csv we get 300 important features.
s
\section{June 5, 2025}
\subsection*{Frequently Forgotten Things}
\begin{itemize}
    \item \textbf{processed\_metasub.csv:} This is all the dataset which contains all the information about different species. This is obtained after processing the 
    raw metasub data. We remove certain cities that are porrly represented and perfrom a bit pre-processing. This dataset should be considered as the starting point 
    for writing any code.
    \item \textbf{metasub\_global\_git.csv:} This is the dataset that contains the Geographically Informative Taxa (GITs) that are used for training the XGBoost model.
\end{itemize}


% July 19th, 2025
\section{July 19, 2025}
I am just keep a track of the things that I have done so far. This part consists of the scripts that I have written and the models that I have created.
 
\section*{/home/chandru/binp37/scripts/ensemble/}
This is the root directory for the ensemble modeling scripts.
\begin{itemize}
    \item \textbf{\texttt{main.py}}: This is the main entry point for the ensemble pipeline. It imports all the different models from the subdirectories, handles data loading and preprocessing (specifically for a hierarchical prediction task), and likely orchestrates the training and evaluation of the ensemble.
\end{itemize}

\subsection*{/home/chandru/binp37/scripts/ensemble/catboost\_ensemble/}
This folder contains scripts related to the CatBoost model.
\begin{itemize}
    \item \textbf{\texttt{catboost\_classification.py}}: Implements a \texttt{CatBoostTuner} class for training and tuning a CatBoost classifier. It uses Optuna for hyperparameter optimization and includes methods for training, evaluation, and running the full pipeline.
\end{itemize}

\subsection*{/home/chandru/binp37/scripts/ensemble/ft\_transformer/}
This folder is for the FT-Transformer model, a state-of-the-art architecture for tabular data.
\begin{itemize}
    \item \textbf{\texttt{ft\_transformer\_classification.py}}: Implements a classifier using the FT-Transformer model. It includes \texttt{FTClassifier} for training/evaluation and \texttt{FTTransformerTuner} for hyperparameter tuning with Optuna.
\end{itemize}

\subsection*{/home/chandru/binp37/scripts/ensemble/grownet/}
This folder contains scripts for GrowNet, a gradient boosting framework using neural networks.
\begin{itemize}
    \item \textbf{\texttt{grownet\_classification.py}}: Implements a \texttt{GrowNetClassifier} for classification tasks. It uses a series of small MLPs trained sequentially. It also includes a \texttt{GrowNetTuner} for hyperparameter optimization.
    \item \textbf{\texttt{grownet\_regressor.py}}: Implements a \texttt{GrowNetRegressor} for regression tasks, following the same boosting principle as the classifier. It also has a corresponding \texttt{GrowNetTuner}.
\end{itemize}

\subsection*{/home/chandru/binp37/scripts/ensemble/lightgbm\_ensemble\_model/}
This folder is for the LightGBM model.
\begin{itemize}
    \item \textbf{\texttt{lightgbm\_classification.py}}: Implements a \texttt{LightGBMTuner} class for training and tuning a LightGBM classifier. It uses Optuna for hyperparameter search and provides functions to train and evaluate the model.
\end{itemize}

\subsection*{/home/chandru/binp37/scripts/ensemble/random\_forest/}
This folder is for the Random Forest model.
\begin{itemize}
    \item \textbf{\texttt{randomforest\_classification.py}}: Contains a \texttt{RandomForestTuner} class that defines a complete pipeline (\texttt{run\_complete\_pipeline}) for tuning, training, and evaluating a Random Forest classifier.
\end{itemize}

\subsection*{/home/chandru/binp37/scripts/ensemble/simple\_nn/}
This folder contains scripts for simple, fully-connected neural networks.
\begin{itemize}
    \item \textbf{\texttt{nn\_classification.py}}: Implements an \texttt{NNTuner} class to find the best hyperparameters for a neural network classifier using Optuna.
    \item \textbf{\texttt{nn\_regression.py}}: Contains an \texttt{NNTuner} class for tuning a neural network regressor, optimizing for a regression metric.
\end{itemize}

\subsection*{/home/chandru/binp37/scripts/ensemble/xgboost\_ensemble/}
This folder is dedicated to XGBoost models.
\begin{itemize}
    \item \textbf{\texttt{xgboost\_classification.py}}: Implements an \texttt{XGBoostTuner} class for hyperparameter tuning and training of an XGBoost classifier using Optuna.
    \item \textbf{\texttt{xgboost\_regression.py}}: Defines a \texttt{XGBoostRegressorTuner} class, which currently specifies default parameters for an XGBoost regressor.
\end{itemize}

\section*{/home/chandru/binp37/scripts/grownet/}

These scripts implement different versions of the GrowNet model, a gradient boosting framework that uses neural networks as weak learners.


\subsection*{\texttt{hirarchical\_grownet.py}}
This script implements a specialized, hierarchical version of the GrowNet model tailored for a multi-task prediction problem. Its primary goal is to simultaneously predict a hierarchy of geographical labels: continent, city, and geographical coordinates (x, y, z).

\begin{itemize}
    \item \textbf{Hierarchical Structure:} The model architecture is explicitly hierarchical. The prediction for continents is used as an input feature for predicting cities, and both continent and city predictions are used to predict the final coordinates.
    \item \textbf{Multi-Task Learning:} It uses a combined loss function to train all three tasks concurrently.
    \item \textbf{Learnable Uncertainty:} The script employs learnable uncertainty weights (\texttt{log\_sigma}) to automatically balance the contribution of the loss from each task (continent classification, city classification, and coordinate regression). This helps prevent one task from dominating the training process.
    \item \textbf{Custom Boosting:} It uses a custom gradient boosting approach where each new weak learner is trained to correct the residuals of the combined ensemble.
\end{itemize}

\subsection*{\texttt{grownet\_classification.py}}
This script provides a more standard implementation of the GrowNet model for multi-class classification tasks. It follows the core principles of stage-wise training of weak learners.

\begin{itemize}
    \item \textbf{Stage-wise Training:} The model is built by sequentially adding weak learners (\texttt{WeakLearner}). The first learner is trained on the original features, while subsequent learners are trained on the original features concatenated with the cumulative predictions from the previous stages.
    \item \textbf{Corrective Step:} After all weak learners are trained individually, a global "corrective step" is performed to fine-tune all model parameters together, allowing the weak learners to adjust to each other.
    \item \textbf{Simpler Boosting:} This implementation's boosting mechanism is based on passing the cumulative output to the next learner, rather than explicitly calculating and fitting on gradients and Hessians.
    \item \textbf{Trainer Class:} It includes a \texttt{GrowNetTrainer} class that encapsulates the stage-wise training and corrective step logic.
\end{itemize}

\subsection*{\texttt{grownet\_classification\_revised.py}}
This script is a revised, more robust, and theoretically grounded implementation of GrowNet for classification. It more closely follows the principles of traditional gradient boosting algorithms like XGBoost, but with neural networks.

\begin{itemize}
    \item \textbf{Gradient-based Boosting:} Unlike the previous script, this version explicitly computes first and second-order gradients (gradients and Hessians) of the loss function. Each new weak learner is trained to fit these gradients, which is a more direct application of the gradient boosting framework.
    \item \textbf{Global Corrective Network:} It introduces a separate, global corrective network that is trained at the end to fine-tune the entire ensemble's predictions, offering a final refinement step.
    \item \textbf{Wrapper Class:} It features a high-level \texttt{MicrobiomeGrowNetClassifier} wrapper class that simplifies the entire workflow, including data splitting, training, evaluation, and plotting results.
    \item \textbf{XGBoost Comparison:} The script includes a function to directly train and compare the performance of the GrowNet model against a standard XGBoost classifier on the same dataset, providing a useful performance benchmark.
\end{itemize}


\end{document}