\documentclass{article}
\usepackage{geometry}
\geometry{margin=1in}
\usepackage{titlesec}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{fancyhdr}
\usepackage{enumitem}
\usepackage{booktabs}

% Header and Footer
\pagestyle{fancy}
\fancyhf{}
\rhead{\textbf{Bioinformatics Research Log}}
\rfoot{Page \thepage}

% Title format
\titleformat{\section}{\Large\bfseries}{}{0pt}{}

\title{\textbf{Bioinformatics Research Project Log}}
\author{Chandrashekar CR \\ Supervisor: Dr. Eran Elhaik \\ Lund University}
\date{April 10, 2025}

\begin{document}

\maketitle
\tableofcontents
\newpage

% March 31, 2025
\section{March 31, 2025}

\subsection*{Tasks for the Day}
\begin{itemize}
    \item Understood the mGPS algorithm from the R code and implemented the preprocessing steps.
    \item Set up the working environment and installed all required libraries.
    \item Began tracking the project.
\end{itemize}

\subsection*{Notes and Observations}
\begin{itemize}
    \item Utilizing the \texttt{ai\_env} environment from previous projects and accessing resources on the bioinformatics server.
    \item Initial challenges in understanding the R code are anticipated to decrease with further engagement.
\end{itemize}

% April 1, 2025
\section{April 1, 2025}

\subsection*{Tasks for the Day}
\begin{itemize}
    \item Understood and implemented Recursive Feature Elimination followed by the XGBoost machine learning algorithm with the correct hierarchical steps.
    \item Initialized Git for version control and pushed code to GitHub.
    \item Gained a deeper understanding of cross-validation principles.
\end{itemize}

\subsection*{Notes and Observations}
\begin{itemize}
    \item Achieved a general understanding of the workflow and added comments to the MetaSUB preprocessing script in R.
    \item Acquired knowledge regarding the importance of cross-validation, although implementation is pending.
\end{itemize}

% April 2, 2025
\section{April 2, 2025}

\subsection*{Tasks for the Day}
\begin{itemize}
    \item Acquired information from Vignesh regarding access to the LUNARC server.
    \item Determined that reimplementing the exact XGBoost model is unnecessary; the focus is on understanding the input data preprocessing.
\end{itemize}

\subsection*{Notes and Observations}
\begin{itemize}
    \item Git repository initialized for the project, tracking all files except data and research papers.
    \item The \texttt{metasub\_global\_git.csv} file contains the Geographically Informative Taxa (GITs) required for the XGBoost model.
    \item The primary objective is to comprehend the preprocessing of input data for XGBoost.
    \item Key questions identified: What is the shape of the input data? What are the prediction targets?
\end{itemize}

% April 3, 2025
\section{April 3, 2025}

\subsection*{Tasks for the Day}
\begin{itemize}
    \item Implemented basic neural network architectures in PyTorch. Hyperparameter tuning indicates that 200 GITs are sufficient for accurate predictions, despite the dataset containing \( n \) data points.
    \item Integrated Ray parallel processing to optimize hyperparameters, aiming to reduce the estimated 4-5 hour search time.
    \item Preprocessed data into numerical format by converting categorical variables (continents and cities) using one-hot encoding.
    \item Deferred the implementation of stratified K-fold cross-validation for later.
\end{itemize}

\subsection*{Notes and Observations}
\begin{itemize}
    \item Successfully logged into the LUNARC server's login node, but GPU access and utilization for neural network training require further investigation.
    \item Authentication and login to LUNARC are complete; however, assistance is needed to understand:
    \begin{itemize}
        \item The location of allocated storage.
        \item The process of submitting jobs using SBATCH.
        \item The fundamentals of working on High-Performance Computing (HPC).
    \end{itemize}
    \item Following Recursive Feature Elimination (RFE), the final dataset has a shape of \(4070 \times 204\), with 200 features and 4 target variables.
    \item Each data point comprises 200 features (GITs) representing the relative sequence abundance (RSA) of microorganisms. The 4 target variables are continent, city, latitude, and longitude.
    \item The dataset includes samples from 40 unique cities across 7 continents.
    \item Categorical variables (continent and city) were encoded using \texttt{sklearn}'s \texttt{LabelEncoder}, while latitude and longitude were standardized using \texttt{StandardScaler}.
    \item Initial consideration of stratified cross-validation was temporarily replaced with \texttt{train\_test\_split} for initial model development. Stratified cross-validation will be revisited for enhanced model performance.
\end{itemize}

\subsubsection*{Neural Network Architecture}
\begin{itemize}
    \item The initial model is a simple feedforward neural network, inspired by the hierarchical structure of the previous XGBoost study.
    \item The first version includes an input layer (200 nodes), two hidden layers (400 nodes each), a smaller hidden layer (2 nodes), and an output layer (7 nodes for the 7 continents).
    \item The plan is to initially train this model to predict the continent. Subsequently, the predicted continent probabilities will be concatenated with the original 200 features as input for a second neural network (similar architecture) to predict the city.
    \item The optimal handling of latitude and longitude values within the neural network remains an open question.
    \item Long training times due to CPU-based computation on the bioinformatics server are a significant challenge. GPU access on the LUNARC cluster is required.
\end{itemize}

% April 4, 2025
\section{April 4, 2025}

\subsection*{Tasks for the Day}
\begin{itemize}
    \item Finalized the presentation for the weekly lab meeting.
    \item Focused on obtaining GPU access and understanding HPC architecture.
    \item Initiated preprocessing for marine and soil datasets, aiming for modular script design applicable to all datasets.
\end{itemize}

\subsection*{Notes and Observations}
Explored various neural network implementations and gained initial understanding of HPC principles.

% April 7, 2025
\section{April 7, 2025}

\subsection*{Tasks for the Day}
\begin{itemize}
    \item Developed a functional neural network to predict all target variables (continent, city, latitude, and longitude).
    \item Completed preprocessing steps for marine and soil datasets.
    \item Began modularizing code for efficient execution on the HPC.
\end{itemize}

\subsection*{Notes and Observations}
\begin{itemize}
    \item Developed a working script for MetaSUB data processing, with pending error handling and file format validation.
    \item Created a working script to extract relevant features using Recursive Feature Elimination with a Random Forest base model.
    \item Initiated work on the HPC, understanding basic operations and starting to modularize scripts for GPU compute nodes.
\end{itemize}

% April 8, 2025
\section{April 8, 2025}
\subsection*{Notes and Observations}
\begin{itemize}
    \item Started building multiple neural network models.
    \item Began learning batch scripting using SLURM.
\end{itemize}

% April 10, 2025
\section{April 10, 2025}
\subsection*{Notes and Observations}
\begin{itemize}
    \item Exploring alternative scaling methods for latitude and longitude, including conversion to radians and trigonometric transformation into a two-dimensional space.
\end{itemize}

% April 11, 2025
\section{April 11, 2025}
\subsection*{Tasks for the day}
\begin{itemize}
    \item These are some of my thoughts. The currrent approach is always making a new neural network model from scratch for each dataset. A final model should be made 
    that utilizes all the iterations done and must work for all type of datasets regardless of the layers of predictions. 
    \item For example, the MetaSUB dataset contains informaiton on the continent, city, latitude and longitude. Whereas the marine dataset contain information only the sea, latitude and longitude.
    There should be a way that can handle these cases instead of definfing a newtwork from scratch.
    \item Finish the logic for the latitude and longitude neural network model. 
    \item Compare the three models with metasub dataset on accuracy, confusion matrix, plot on world map.
\end{itemize}

% April 14, 2025
\section{April 14, 2025}

\subsection*{Notes and Observations}
\begin{itemize}
    \item \textbf{Combined Models Generally Outperform Separate Models:} Models 2 (nn\_model\_combined.py) and 4 (nn\_combined\_model\_lat\_long.py), which employ combined or hierarchical architectures, tend to show better performance, particularly on the latitude and longitude/XYZ prediction tasks, compared to Model 1 (nn\_model.py) and Model 3 (nn\_model\_lat\_long.py) which use separate networks.
    
    \item \textbf{XYZ Coordinate Transformation Seems Beneficial:} Models 3 and 4, which incorporate the transformation of latitude and longitude into XYZ coordinates, demonstrate significantly lower Mean Absolute Errors for these predictions compared to Model 1, which predicts latitude and longitude directly.
    
    \item \textbf{Trade-offs Between Classification and Regression:} There isn't one single model that dominates across all tasks. Some models show higher accuracy for continent and city prediction, while others excel in latitude and longitude prediction.
    
    \item \textbf{Overfitting:} In several instances, the training accuracy is notably higher than the test accuracy, suggesting some degree of overfitting across the models. This is a common challenge in machine learning and something to consider for future improvements.
\end{itemize}

\subsection*{Model-by-Model Comparison}
\begin{itemize}
    \item \textbf{Model 1: nn\_model.py (Right Top Corner)}
    \begin{itemize}
        \item \textbf{Continent Prediction:} Strong test accuracy (89.56\%) with balanced precision, recall, and F1-score.
        \item \textbf{Cities Prediction:} Lower test accuracy (78.75\%) compared to continent prediction.
        \item \textbf{Latitude and Longitude Prediction:} High MAEs (0.3964 and 0.3445). Maps show significant spread between predictions and true locations.
        \item \textbf{Architecture:} Uses separate networks for each task, which may limit learning of shared representations.
    \end{itemize}

    \item \textbf{Model 2: nn\_model\_combined.py (Left Bottom Corner)}
    \begin{itemize}
        \item \textbf{Continent Prediction:} Slightly lower test accuracy (88.33\%) than Model 1.
        \item \textbf{Cities Prediction:} Improved test accuracy (81.82\%) with higher precision and F1-score.
        \item \textbf{Latitude and Longitude Prediction:} Lowest MAEs (0.2230 and 0.1876). Very accurate predictions, as confirmed by maps.
        \item \textbf{Architecture:} Hierarchical structure facilitates learning between tasks.
    \end{itemize}

    \item \textbf{Model 3: nn\_model\_lat\_long.py (Right Bottom Corner)}
    \begin{itemize}
        \item \textbf{Continent Prediction:} High test accuracy (89.31\%).
        \item \textbf{Cities Prediction:} Lowest test accuracy (75.92\%) among all models.
        \item \textbf{Latitude and Longitude Prediction:} Very high MAEs (8.5982 and 21.2971). Severe scatter on maps.
        \item \textbf{Architecture:} Uses XYZ internally but has poor coordinate prediction, possibly due to flawed transformations or output layers.
    \end{itemize}

    \item \textbf{Model 4: nn\_combined\_model\_lat\_long.py (Left Top Corner)}
    \begin{itemize}
        \item \textbf{Continent Prediction:} Slightly lower test accuracy (87.35\%).
        \item \textbf{Cities Prediction:} Highest test accuracy (82.92\%) among all models.
        \item \textbf{Latitude and Longitude Prediction:} Low MAEs (4.5070 and 14.4377), but not as low as Model 2.
        \item \textbf{Architecture:} Combines hierarchical structure with XYZ usage, effective for cities and coordinates.
    \end{itemize}
\end{itemize}

\subsection*{Comparative Analysis and Best Model}
\begin{itemize}
    \item \textbf{Best for Coordinates:} Model 2 clearly outperforms others in latitude and longitude prediction.
    \item \textbf{Best for Cities:} Model 4 achieves the highest accuracy.
    \item \textbf{Continent Accuracy:} All models perform similarly well.
    \item \textbf{Overall Best Model:} Model 2 (nn\_model\_combined.py) is the most well-rounded, offering competitive classification accuracy and the best coordinate prediction performance.
\end{itemize}

\subsection*{Opportunities for Improvement}
\begin{itemize}
    \item \textbf{Reduce Overfitting:} Apply techniques like dropout, L1/L2 regularization, or early stopping.
    \item \textbf{Fix Model 3:} Investigate XYZ conversion and back-transformation.
    \item \textbf{Refine Hierarchical Designs:} Experiment with alternative fusion strategies or attention mechanisms.
    \item \textbf{Ensemble Strategies:} Combining predictions may improve performance across tasks.
\end{itemize}


% April 16th, 2025

\section{June 4, 2025}
Performing recursive feature selection on the tax_metasub_data.csv we get 300 important features.

\section{June 5, 2025}
\subsection*{Frequently Forgotten Things}
\begin{itemize}
    \item \textbf{processed_metasub.csv:} This is all the dataset which contains all the information about different species. This is obtained after processing the 
    raw metasub data. We remove certain cities that are porrly represented and perfrom a bit pre-processing. This dataset should be considered as the starting point 
    for writing any code.

\end{document}