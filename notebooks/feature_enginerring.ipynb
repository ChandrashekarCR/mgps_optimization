{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "import os\n",
    "import geopandas as gpd\n",
    "from Bio import Entrez\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "from Bio import Entrez\n",
    "import gzip\n",
    "import subprocess \n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data \n",
    "df = pd.read_csv(\"/home/chandru/binp37/results/metasub/processed_metasub.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_df = pd.read_csv(\"/home/chandru/binp37/results/metasub/metasub_training_testing_data.csv\")\n",
    "rfe_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geograpical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data = df[['city_total_population','city_population_density',\n",
    "                  'city_land_area_km2','city_ave_june_temp_c','city_elevation_meters','city_koppen_climate','continent','city','latitude','longitude']]\n",
    "\n",
    "# Fix city elevation of hanoi, yamaguchi in meters\n",
    "feature_data.loc[feature_data['city'] == 'hanoi','city_elevation_meters'] = 12\n",
    "feature_data.loc[feature_data['city'] == 'yamaguchi','city_elevation_meters'] = 23\n",
    "feature_data.loc[feature_data['city'] == 'marseille','city_elevation_meters'] = 42 # city elevation of marseille on google is 42 m here it is 0\n",
    "\n",
    "# Get city population density, city ladn ares in km2, city avg temp in june and city elevation in meters of offa \n",
    "offa_data = {\n",
    "    'city_population_density': 2500.0,\n",
    "    'city_land_area_km2': 74.0,\n",
    "    'city_ave_june_temp_c': 28.0,\n",
    "    'city_elevation_meters': 457.0\n",
    "}\n",
    "\n",
    "feature_data.loc[feature_data['city'] == 'offa', list(offa_data.keys())] = list(offa_data.values())\n",
    "\n",
    "# Get city land area in km2 of marseille  \n",
    "feature_data.loc[feature_data['city'] == 'marseille','city_land_area_km2'] = 240\n",
    "\n",
    "# Fix all the nan values of london\n",
    "london_data = {\n",
    "    'city_total_population': 8787892.0,\n",
    "    'city_population_density': 5590.0,\n",
    "    'city_land_area_km2': 1572.0,\n",
    "    'city_ave_june_temp_c': 14.4,\n",
    "    'city_elevation_meters': 11.0,\n",
    "    'city_koppen_climate': 'marine_west_coast_climate'\n",
    "}\n",
    "feature_data.loc[feature_data['city'] == 'london', list(london_data.keys())] = list(london_data.values())\n",
    "\n",
    "\n",
    "feature_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for skewness in the data before appling long transformer -> \n",
    "# Note to self: The city_land_area_km2 is right skewed, so we will go with log scale transformation\n",
    "#             : The city_elevation_meters is multi modal there we will go with QuantileTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, QuantileTransformer, OneHotEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Define input columns\n",
    "#log_cols = ['city_land_area_km2']\n",
    "#quantile_cols = ['city_elevation_meters']\n",
    "scale_cols = ['city_total_population', 'city_ave_june_temp_c']\n",
    "cat_cols = ['city_koppen_climate']\n",
    "\n",
    "# Step 2: Log-transform function\n",
    "#def safe_log1p(x):\n",
    "#    return np.log1p(np.maximum(x, 0))\n",
    "\n",
    "# Step 3: Create log pipeline\n",
    "#log_pipeline = Pipeline([\n",
    "#    ('log', FunctionTransformer(safe_log1p)),\n",
    "#    ('scale', StandardScaler())\n",
    "#])\n",
    "\n",
    "# Step 4: Build the ColumnTransformer\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "#    ('log', log_pipeline, log_cols),\n",
    "#    ('quantile', QuantileTransformer(output_distribution='normal'), quantile_cols),\n",
    "    ('scale', StandardScaler(), scale_cols),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)\n",
    "])\n",
    "\n",
    "# Step 5: Fit and transform\n",
    "geo_features_processed = preprocessor.fit_transform(feature_data)\n",
    "\n",
    "# Step 6: Extract column names correctly\n",
    "output_feature_names = []\n",
    "\n",
    "for name, transformer, cols in preprocessor.transformers_:\n",
    "    if name == 'cat':\n",
    "        # For OneHotEncoder\n",
    "        encoder = transformer\n",
    "        if isinstance(encoder, Pipeline):\n",
    "            encoder = encoder.named_steps['onehot']\n",
    "        cats = encoder.categories_[0]\n",
    "        output_feature_names.extend([f\"{cols[0]}_{cat}\" for cat in cats])\n",
    "    else:\n",
    "        output_feature_names.extend(cols)\n",
    "\n",
    "# Step 7: Convert to DataFrame\n",
    "geo_features_df = pd.DataFrame(geo_features_processed)\n",
    "\n",
    "# Step 8: Merge with main features (RFE-selected ones)\n",
    "final_df = pd.concat([rfe_df, geo_features_df], axis=1)\n",
    "final_df.to_csv(\"/home/chandru/binp37/results/metasub/metasub_geo_training_testing.csv\", index=False)\n",
    "\n",
    "print(\"Final dataset shape:\", final_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Select your input columns\n",
    "scale_cols = ['city_ave_june_temp_c']\n",
    "#cat_cols = ['city_koppen_climate']\n",
    "\n",
    "# Step 2: Create preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('scale', StandardScaler(), scale_cols),\n",
    "#        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Step 3: Fit and transform the geo feature data\n",
    "geo_features_processed = preprocessor.fit_transform(feature_data)\n",
    "\n",
    "# Step 4: Get feature names\n",
    "feature_names = []\n",
    "\n",
    "# Handle scaled columns\n",
    "feature_names.extend(scale_cols)\n",
    "\n",
    "# Handle one-hot columns\n",
    "#ohe = preprocessor.named_transformers_['cat']\n",
    "#cat_feature_names = ohe.get_feature_names_out(cat_cols)\n",
    "#feature_names.extend(cat_feature_names)\n",
    "\n",
    "# Step 5: Convert to DataFrame\n",
    "geo_features_df = pd.DataFrame(geo_features_processed.toarray() if hasattr(geo_features_processed, 'toarray') else geo_features_processed)\n",
    "\n",
    "# Step 6: Merge with selected features and save\n",
    "final_df = pd.concat([rfe_df.reset_index(drop=True), geo_features_df.reset_index(drop=True)], axis=1)\n",
    "#final_df.to_csv(\"/home/chandru/binp37/results/metasub/metasub_geo_training_testing.csv\", index=False)\n",
    "\n",
    "print(\"Final dataset shape:\", final_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/chandru/binp37/results/metasub/metasub_geo_training_testing.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microbiome features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can get the raw sequence of all these top hundered species and get a phylogenetic tree to determine the relationship between species.\n",
    "# We can then use the information as well as a feature to predict the lat and long.\n",
    "\n",
    "microbe_data = rfe_df.iloc[:,:-4]\n",
    "microbe_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phylogenetic Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_list = []\n",
    "for name in microbe_data.columns:\n",
    "    species_list.append(name)\n",
    "    \n",
    "\n",
    "tax_df = pd.read_csv(\"/home/chandru/binp37/results/metasub/taxonomic_info.csv\")\n",
    "lin_df = tax_df[tax_df['Species'].isin(species_list)].dropna(axis=1,how='all')\n",
    "lin_df = lin_df.dropna(subset=lin_df.columns[1:7]).iloc[:,:7]\n",
    "lin_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(lin_df['Rank_1'],return_counts=True)[0],np.unique(lin_df['Rank_1'],return_counts=True)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count values\n",
    "counts = lin_df['Rank_2'].value_counts()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(6, 4))\n",
    "counts.plot(kind='bar', color=['tomato', 'skyblue'])\n",
    "plt.title('Frequency of Rank_1 Categories')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Entrez.email = \"1ms19bt011@gmail.com\" # Remember to set your actual email\n",
    "\n",
    "def download_genome(species, output_dir=\"genomes\"):\n",
    "    \"\"\"\n",
    "    Downloads the complete genome for a given species from NCBI RefSeq,\n",
    "    handling both FTP and HTTP URLs.\n",
    "\n",
    "    Args:\n",
    "        species (str): The scientific name of the species (e.g., \"Escherichia coli\").\n",
    "        output_dir (str): The directory where the genome file will be saved.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the genome was successfully downloaded and decompressed, False otherwise.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    search_terms = [\n",
    "        f'\"{species}\"[Organism] AND \"complete genome\"[Assembly Level]',\n",
    "        f'\"{species}\"[Organism] AND \"reference genome\"[Refseq Category]',\n",
    "        f'\"{species}\"[Organism] AND latest[filter]',\n",
    "        f'\"{species}\"[Organism]' # Broadest term as a last resort\n",
    "    ]\n",
    "\n",
    "    for term_index, term in enumerate(search_terms):\n",
    "        print(f\"Searching for '{species}' with term: '{term}'\")\n",
    "        try:\n",
    "            # Search for latest RefSeq assembly\n",
    "            handle = Entrez.esearch(db=\"assembly\", term=term, retmax=1)\n",
    "            record = Entrez.read(handle)\n",
    "            handle.close() # Always close the handle\n",
    "\n",
    "            if record[\"IdList\"]:\n",
    "                assembly_id = record[\"IdList\"][0]\n",
    "                print(f\"Found assembly ID: {assembly_id} for {species}\")\n",
    "\n",
    "                # Fetch summary to get FTP path\n",
    "                summary_handle = Entrez.esummary(db=\"assembly\", id=assembly_id)\n",
    "                doc = Entrez.read(summary_handle)\n",
    "                summary_handle.close() # Always close the handle\n",
    "\n",
    "                ftp_path = doc[\"DocumentSummarySet\"][\"DocumentSummary\"][0][\"FtpPath_RefSeq\"]\n",
    "                if ftp_path:\n",
    "                    filename_stem = ftp_path.split(\"/\")[-1]\n",
    "                    fasta_url = f\"{ftp_path}/{filename_stem}_genomic.fna.gz\"\n",
    "                    output_gz_path = os.path.join(output_dir, f\"{species.replace(' ', '_')}.fna.gz\")\n",
    "                    output_fna_path = os.path.join(output_dir, f\"{species.replace(' ', '_')}.fna\")\n",
    "\n",
    "                    print(f\"Attempting to download from: {fasta_url}\")\n",
    "\n",
    "                    try:\n",
    "                        if fasta_url.startswith(\"ftp://\"):\n",
    "                            # Use wget for FTP paths\n",
    "                            print(f\"Using wget for FTP download: {fasta_url}\")\n",
    "                            # -q for quiet, -O for output file, --show-progress for progress bar\n",
    "                            # --no-verbose for cleaner output\n",
    "                            # Use subprocess.run for better control and error handling than os.system\n",
    "                            result = subprocess.run(\n",
    "                                [\"wget\", \"--no-verbose\", \"--show-progress\", \"-O\", output_gz_path, fasta_url],\n",
    "                                check=True, # Raise CalledProcessError if wget returns non-zero exit code\n",
    "                                capture_output=True, # Capture stdout/stderr for debugging if needed\n",
    "                                text=True # Decode stdout/stderr as text\n",
    "                            )\n",
    "                            # print(result.stdout) # Uncomment for detailed wget output\n",
    "                            # print(result.stderr) # Uncomment for detailed wget output\n",
    "                            print(f\"Downloaded {species} to {output_gz_path} using wget.\")\n",
    "                        else:\n",
    "                            # Use requests for HTTP/HTTPS paths\n",
    "                            print(f\"Using requests for HTTP/HTTPS download: {fasta_url}\")\n",
    "                            response = requests.get(fasta_url, stream=True)\n",
    "                            response.raise_for_status() # Raise an exception for HTTP errors\n",
    "\n",
    "                            total_size_in_bytes = int(response.headers.get('content-length', 0))\n",
    "                            block_size = 1024 # 1 Kibibyte\n",
    "                            progress_bar = tqdm(total=total_size_in_bytes, unit='iB', unit_scale=True, desc=f\"Downloading {species}\")\n",
    "\n",
    "                            with open(output_gz_path, 'wb') as f:\n",
    "                                for chunk in response.iter_content(chunk_size=block_size):\n",
    "                                    progress_bar.update(len(chunk))\n",
    "                                    f.write(chunk)\n",
    "                            progress_bar.close()\n",
    "\n",
    "                            if total_size_in_bytes != 0 and progress_bar.n != total_size_in_bytes:\n",
    "                                print(\"ERROR, something went wrong during download!\")\n",
    "                                return False\n",
    "                            print(f\"Downloaded {species} to {output_gz_path} using requests.\")\n",
    "\n",
    "                        # Decompress the file, regardless of how it was downloaded\n",
    "                        print(f\"Decompressing {output_gz_path}...\")\n",
    "                        with gzip.open(output_gz_path, 'rb') as f_in:\n",
    "                            with open(output_fna_path, 'wb') as f_out:\n",
    "                                f_out.write(f_in.read())\n",
    "                        os.remove(output_gz_path) # Remove the compressed file\n",
    "                        print(f\"Decompressed to {output_fna_path}\")\n",
    "                        return True\n",
    "                    except subprocess.CalledProcessError as sub_e:\n",
    "                        print(f\"wget failed for {species} from {fasta_url}: {sub_e}\")\n",
    "                        print(f\"wget stdout: {sub_e.stdout}\")\n",
    "                        print(f\"wget stderr: {sub_e.stderr}\")\n",
    "                        continue # Try next search term\n",
    "                    except requests.exceptions.RequestException as req_e:\n",
    "                        print(f\"Download failed for {species} from {fasta_url}: {req_e}\")\n",
    "                        continue # Try next search term\n",
    "                    except Exception as download_e:\n",
    "                        print(f\"An unexpected error occurred during download/decompression for {species}: {download_e}\")\n",
    "                        continue # Try next search term\n",
    "                else:\n",
    "                    print(f\"No FTP path found for {species} with term '{term}'. Trying next search term.\")\n",
    "            else:\n",
    "                print(f\"No assembly found for {species} with term '{term}'. Trying next search term.\")\n",
    "            time.sleep(1) # Small delay between Entrez calls to be polite\n",
    "        except Exception as e:\n",
    "            print(f\"Error during Entrez search for {species} with term '{term}': {e}\")\n",
    "            time.sleep(2) # Longer delay if Entrez call itself fails\n",
    "    print(f\"Failed to download genome for {species} after trying all search terms.\")\n",
    "    return False\n",
    "\n",
    "\n",
    "output_directory = \"genomes\"\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Process each species in the list\n",
    "print(\"\\nStarting genome download process...\")\n",
    "for species in tqdm(filtered_species_list[:], desc=\"Overall Genome Download Progress\"):\n",
    "    print(f\"\\nProcessing species: {species}\")\n",
    "    success = download_genome(species, output_directory)\n",
    "    if not success:\n",
    "        print(f\"Could not download genome for {species}. Please check the species name or try again later.\")\n",
    "    time.sleep(2) # Respect NCBI rate limits between species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clutering using K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elbow method to determine ideal cluster size -> Note I am getting the cut iff to be 15.\n",
    "# Calculate inertia for k=1 to 50\n",
    "inertias = []\n",
    "for k in range(1, 50):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(np.array(microbe_data))\n",
    "    inertias.append(kmeans.inertia_)\n",
    "\n",
    "# Plot Elbow Curve\n",
    "plt.plot(range(1, 50), inertias, marker='o')\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=15, random_state=42, n_init=\"auto\").fit(np.array(microbe_data))\n",
    "kmeans.cluster_centers_\n",
    "\n",
    "\n",
    "centorid_distances = cdist(np.array(microbe_data),kmeans.cluster_centers_,\"euclidean\")\n",
    "closet_indices = np.argmin(centorid_distances,axis=0)\n",
    "\n",
    "augment_data = pd.concat([microbe_data,pd.DataFrame(centorid_distances)],axis=1)\n",
    "augment_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continents: 7 (['east_asia' 'europe' 'middle_east' 'north_america' 'oceania'\n",
      " 'south_america' 'sub_saharan_africa'])\n",
      "Cities: 40\n",
      "Continuous features: 200\n"
     ]
    }
   ],
   "source": [
    "# Data processing function for hierarchical model\n",
    "def process_data_hierarchical(df):\n",
    "    \"\"\"Process data for hierarchical prediction\"\"\"\n",
    "    # Process continuous features\n",
    "    cont_cols = [col for col in df.columns if col not in [\n",
    "        'latitude', 'longitude',\n",
    "        'latitude_rad', 'longitude_rad', 'x', 'y', 'z',\n",
    "        'scaled_x', 'scaled_y', 'scaled_z', 'continent', 'city'\n",
    "    ]]\n",
    "    \n",
    "    # Get the features\n",
    "    x_cont = df[cont_cols].values\n",
    "    \n",
    "    # Encode continent labels\n",
    "    continent_encoder = LabelEncoder()\n",
    "    y_continent = continent_encoder.fit_transform(df['continent'].values)\n",
    "    \n",
    "    # Encode city labels\n",
    "    city_encoder = LabelEncoder()\n",
    "    y_city = city_encoder.fit_transform(df['city'].values)\n",
    "    \n",
    "    # Calculate coordinates if not already present\n",
    "    if not all(col in df.columns for col in ['x', 'y', 'z']):\n",
    "        df['latitude_rad'] = np.deg2rad(df['latitude'])\n",
    "        df['longitude_rad'] = np.deg2rad(df['longitude'])\n",
    "        df['x'] = np.cos(df['latitude_rad']) * np.cos(df['longitude_rad'])\n",
    "        df['y'] = np.cos(df['latitude_rad']) * np.sin(df['longitude_rad'])\n",
    "        df['z'] = np.sin(df['latitude_rad'])\n",
    "    \n",
    "    # Scale coordinates\n",
    "    coord_scaler = StandardScaler()\n",
    "    y_coords = coord_scaler.fit_transform(df[['x', 'y', 'z']].values)\n",
    "    \n",
    "    continents = continent_encoder.classes_\n",
    "    cities = city_encoder.classes_\n",
    "    \n",
    "    print(f\"Continents: {len(continents)} ({continents})\")\n",
    "    print(f\"Cities: {len(cities)}\")\n",
    "    print(f\"Continuous features: {len(cont_cols)}\")\n",
    "    \n",
    "    return {\n",
    "        'x_cont': x_cont,\n",
    "        'y_continent': y_continent,\n",
    "        'y_city': y_city,\n",
    "        'y_coords': y_coords, # This is for neural networks. Scaling is required\n",
    "        'y_latitude': df['latitude'].values, # This is for XGBoost, we don't need to scale this\n",
    "        'y_longitude':df['longitude'].values, # This is for XGBoost, we don't need to scale this\n",
    "        'encoders': {\n",
    "            'continent': continent_encoder,\n",
    "            'city': city_encoder,\n",
    "            'coord': coord_scaler\n",
    "        },\n",
    "        'continents': continents,\n",
    "        'cities': cities\n",
    "    }\n",
    "\n",
    "df = pd.read_csv(\"/home/chandru/binp37/results/metasub/metasub_training_testing_data.csv\")\n",
    "processed_data = process_data_hierarchical(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['east_asia', 'europe', 'middle_east', 'north_america', 'oceania',\n",
       "       'south_america', 'sub_saharan_africa'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data['continents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/home/chandru/binp37/scripts/ensemble\")\n",
    "y_test_cont = np.load(\"saved_results/y_test_cont.npy\")\n",
    "y_pred_cont = np.load(\"saved_results/y_pred_cont.npy\")\n",
    "\n",
    "y_test_city = np.load(\"saved_results/y_test_city.npy\")\n",
    "y_pred_city = np.load(\"saved_results/y_pred_city.npy\")\n",
    "\n",
    "y_test_coords = np.load(\"saved_results/y_test_coord.npy\")\n",
    "y_pred_coords = np.load(\"saved_results/y_pred_coord.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'true_cont': y_test_cont,\n",
    "    'pred_cont': y_pred_cont,\n",
    "    'true_city': y_test_city,\n",
    "    'pred_city': y_pred_city,\n",
    "    'true_lat': y_test_coords[:, 0],\n",
    "    'true_lon': y_test_coords[:, 1],\n",
    "    'pred_lat': y_pred_coords[:, 0],\n",
    "    'pred_lon': y_pred_coords[:, 1]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "continents = np.array([\n",
    "    'east_asia', 'europe', 'middle_east', 'north_america',\n",
    "    'oceania', 'south_america', 'sub_saharan_africa'\n",
    "])\n",
    "\n",
    "cities = np.array([\n",
    "    'auckland', 'baltimore', 'barcelona', 'berlin', 'bogota', 'brisbane',\n",
    "    'denver', 'doha', 'europe', 'fairbanks', 'hamilton', 'hanoi',\n",
    "    'hong_kong', 'ilorin', 'kuala_lumpur', 'kyiv', 'lisbon', 'london',\n",
    "    'marseille', 'minneapolis', 'naples', 'new_york_city', 'offa', 'oslo',\n",
    "    'paris', 'rio_de_janeiro', 'sacramento', 'san_francisco', 'santiago',\n",
    "    'sao_paulo', 'sendai', 'seoul', 'singapore', 'sofia', 'stockholm',\n",
    "    'taipei', 'tokyo', 'vienna', 'yamaguchi', 'zurich'\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['true_cont_name'] = df['true_cont'].map(lambda i: continents[i])\n",
    "df['pred_cont_name'] = df['pred_cont'].map(lambda i: continents[i])\n",
    "\n",
    "df['true_city_name'] = df['true_city'].map(lambda i: cities[i])\n",
    "df['pred_city_name'] = df['pred_city'].map(lambda i: cities[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_support_map = dict(zip(np.unique(df['true_cont_name'],return_counts=True)[0],np.unique(df['true_cont_name'],return_counts=True)[1]))\n",
    "city_support_map = dict(zip(np.unique(df['true_city_name'],return_counts=True)[0],np.unique(df['true_city_name'],return_counts=True)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Compute the correctness \n",
    "df['continent_correct'] = df['true_cont'] == df['pred_cont']\n",
    "df['city_correct'] = df['true_city'] == df['pred_city']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Compute coordinates distance\n",
    "\n",
    "# Distance between two points on the earth\n",
    "def haversine_distance(lat1,lon1,lat2,lon2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points on the earth\n",
    "    \"\"\"\n",
    "    # Radius of the earth\n",
    "    R = 6371.0\n",
    "\n",
    "    # Convert from degrees to radians\n",
    "    lat1_rad = np.radians(lat1)\n",
    "    lon1_rad = np.radians(lon1)\n",
    "    lat2_rad = np.radians(lat2)\n",
    "    lon2_rad = np.radians(lon2)\n",
    "\n",
    "    dlat = lat2_rad - lat1_rad\n",
    "    dlon = lon2_rad - lon1_rad\n",
    "\n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1_rad) * np.cos(lat2_rad) * np.sin(dlon/2) **2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "\n",
    "    return R * c # in kilometers\n",
    "\n",
    "\n",
    "\n",
    "df['coord_error'] = haversine_distance(df['true_lat'].values,df['true_lon'].values,df['pred_lat'].values,df['pred_lon'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The median distance error is 17.84439468383789\n",
      "The mean distance error is 727.4476318359375\n",
      "The max distance error is 15990.0634765625\n"
     ]
    }
   ],
   "source": [
    "print(f'The median distance error is {np.median(df['coord_error'].values)}')\n",
    "print(f'The mean distance error is {np.mean(df['coord_error'].values)}')\n",
    "print(f'The max distance error is {np.max(df['coord_error'].values)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 largest coordinate errors:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_city_name</th>\n",
       "      <th>pred_city_name</th>\n",
       "      <th>true_cont_name</th>\n",
       "      <th>pred_cont_name</th>\n",
       "      <th>true_lat</th>\n",
       "      <th>pred_lat</th>\n",
       "      <th>true_lon</th>\n",
       "      <th>pred_lon</th>\n",
       "      <th>coord_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>brisbane</td>\n",
       "      <td>sao_paulo</td>\n",
       "      <td>oceania</td>\n",
       "      <td>east_asia</td>\n",
       "      <td>-27.431326</td>\n",
       "      <td>48.476173</td>\n",
       "      <td>153.074997</td>\n",
       "      <td>11.324935</td>\n",
       "      <td>15990.063477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>sao_paulo</td>\n",
       "      <td>sao_paulo</td>\n",
       "      <td>south_america</td>\n",
       "      <td>east_asia</td>\n",
       "      <td>-23.561726</td>\n",
       "      <td>16.010761</td>\n",
       "      <td>-46.656693</td>\n",
       "      <td>88.357361</td>\n",
       "      <td>15253.044922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>singapore</td>\n",
       "      <td>kyiv</td>\n",
       "      <td>east_asia</td>\n",
       "      <td>east_asia</td>\n",
       "      <td>1.298330</td>\n",
       "      <td>-15.619979</td>\n",
       "      <td>103.798027</td>\n",
       "      <td>-33.606396</td>\n",
       "      <td>15081.753906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>hamilton</td>\n",
       "      <td>auckland</td>\n",
       "      <td>oceania</td>\n",
       "      <td>oceania</td>\n",
       "      <td>-37.783329</td>\n",
       "      <td>40.442173</td>\n",
       "      <td>175.283325</td>\n",
       "      <td>-69.655579</td>\n",
       "      <td>14534.150391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>london</td>\n",
       "      <td>london</td>\n",
       "      <td>europe</td>\n",
       "      <td>europe</td>\n",
       "      <td>51.480598</td>\n",
       "      <td>-15.746110</td>\n",
       "      <td>-0.194938</td>\n",
       "      <td>105.246605</td>\n",
       "      <td>12435.375977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>fairbanks</td>\n",
       "      <td>hamilton</td>\n",
       "      <td>north_america</td>\n",
       "      <td>europe</td>\n",
       "      <td>64.837784</td>\n",
       "      <td>-38.060692</td>\n",
       "      <td>-147.716385</td>\n",
       "      <td>179.087601</td>\n",
       "      <td>11801.385742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>tokyo</td>\n",
       "      <td>barcelona</td>\n",
       "      <td>east_asia</td>\n",
       "      <td>middle_east</td>\n",
       "      <td>35.605324</td>\n",
       "      <td>44.005825</td>\n",
       "      <td>139.682404</td>\n",
       "      <td>-25.795036</td>\n",
       "      <td>11041.908203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>hanoi</td>\n",
       "      <td>ilorin</td>\n",
       "      <td>east_asia</td>\n",
       "      <td>europe</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>9.228308</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>6.301521</td>\n",
       "      <td>10529.858398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>singapore</td>\n",
       "      <td>singapore</td>\n",
       "      <td>east_asia</td>\n",
       "      <td>europe</td>\n",
       "      <td>1.431875</td>\n",
       "      <td>16.023275</td>\n",
       "      <td>103.775139</td>\n",
       "      <td>12.307347</td>\n",
       "      <td>10120.409180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>singapore</td>\n",
       "      <td>yamaguchi</td>\n",
       "      <td>east_asia</td>\n",
       "      <td>east_asia</td>\n",
       "      <td>1.326990</td>\n",
       "      <td>48.476173</td>\n",
       "      <td>103.946732</td>\n",
       "      <td>11.324935</td>\n",
       "      <td>10090.230469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    true_city_name pred_city_name true_cont_name pred_cont_name   true_lat  \\\n",
       "632       brisbane      sao_paulo        oceania      east_asia -27.431326   \n",
       "86       sao_paulo      sao_paulo  south_america      east_asia -23.561726   \n",
       "208      singapore           kyiv      east_asia      east_asia   1.298330   \n",
       "550       hamilton       auckland        oceania        oceania -37.783329   \n",
       "354         london         london         europe         europe  51.480598   \n",
       "70       fairbanks       hamilton  north_america         europe  64.837784   \n",
       "254          tokyo      barcelona      east_asia    middle_east  35.605324   \n",
       "159          hanoi         ilorin      east_asia         europe  21.000000   \n",
       "614      singapore      singapore      east_asia         europe   1.431875   \n",
       "1        singapore      yamaguchi      east_asia      east_asia   1.326990   \n",
       "\n",
       "      pred_lat    true_lon    pred_lon   coord_error  \n",
       "632  48.476173  153.074997   11.324935  15990.063477  \n",
       "86   16.010761  -46.656693   88.357361  15253.044922  \n",
       "208 -15.619979  103.798027  -33.606396  15081.753906  \n",
       "550  40.442173  175.283325  -69.655579  14534.150391  \n",
       "354 -15.746110   -0.194938  105.246605  12435.375977  \n",
       "70  -38.060692 -147.716385  179.087601  11801.385742  \n",
       "254  44.005825  139.682404  -25.795036  11041.908203  \n",
       "159   9.228308  105.000000    6.301521  10529.858398  \n",
       "614  16.023275  103.775139   12.307347  10120.409180  \n",
       "1    48.476173  103.946732   11.324935  10090.230469  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the DataFrame by 'coord_error' in descending order\n",
    "df_sorted = df.sort_values(by='coord_error', ascending=False)   \n",
    "print(\"Top 10 largest coordinate errors:\")\n",
    "df_sorted[['true_city_name', 'pred_city_name', 'true_cont_name', 'pred_cont_name','true_lat','pred_lat','true_lon','pred_lon',\n",
    "            'coord_error']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC (Continent): 0.935\n",
      "ROC AUC (City): 0.895\n",
      "PRC AUC (Continent): 0.949\n",
      "PRC AUC (City): 0.908\n"
     ]
    }
   ],
   "source": [
    "# Get ROC AUC for continent and city - This a multiclass classification problem\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "# Binarize the true labels for ROC AUC calculation\n",
    "y_true_cont_binarized = label_binarize(y_test_cont, classes=np.arange(len(processed_data['continents'])))\n",
    "y_true_city_binarized = label_binarize(y_test_city, classes=np.arange(len(processed_data['cities'])))\n",
    "\n",
    "# Calculate ROC AUC for continent and city\n",
    "roc_auc_continent = roc_auc_score(y_true_cont_binarized, label_binarize(y_pred_cont, classes=np.arange(len(processed_data['continents']))), average='macro', multi_class='ovr')\n",
    "roc_auc_city = roc_auc_score(y_true_city_binarized, label_binarize(y_pred_city, classes=np.arange(len(processed_data['cities']))), average='macro', multi_class='ovr')\n",
    "\n",
    "# Calculate Precision-Recall AUC for continent and city\n",
    "precision_cont, recall_cont, _ = precision_recall_curve(y_true_cont_binarized.ravel(), label_binarize(y_pred_cont, classes=np.arange(len(processed_data['continents']))).ravel())\n",
    "prc_auc_continent = auc(recall_cont, precision_cont)\n",
    "\n",
    "precision_city, recall_city, _ = precision_recall_curve(y_true_city_binarized.ravel(), label_binarize(y_pred_city, classes=np.arange(len(processed_data['cities']))).ravel())\n",
    "prc_auc_city = auc(recall_city, precision_city)\n",
    "\n",
    "print(f\"ROC AUC (Continent): {roc_auc_continent:.3f}\")\n",
    "print(f\"ROC AUC (City): {roc_auc_city:.3f}\")\n",
    "print(f\"PRC AUC (Continent): {prc_auc_continent:.3f}\")\n",
    "print(f\"PRC AUC (City): {prc_auc_city:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Group into the 4 categories\n",
    "def group_label(row):\n",
    "    if row['continent_correct'] and row['city_correct']:\n",
    "        return 'C_correct Z_correct'\n",
    "    elif row['continent_correct'] and not row['city_correct']:\n",
    "        return 'C_correct Z_wrong'\n",
    "    elif not row['continent_correct'] and row['city_correct']:\n",
    "        return 'C_wrong Z_correct'\n",
    "    else:\n",
    "        return 'C_wrong Z_wrong'\n",
    "\n",
    "df['error_group'] = df.apply(group_label, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Aggregate stats\n",
    "group_stats = df.groupby('error_group')['coord_error'].agg([\n",
    "    ('count', 'count'),\n",
    "    ('mean_error_km', 'mean'),\n",
    "    ('median_error_km', 'median')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Expected Coordinate Error E[D]: 727.45 km\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Calculate proportions and expected error\n",
    "total = len(df)\n",
    "group_stats['proportion'] = group_stats['count'] / total\n",
    "group_stats['weighted_error'] = group_stats['mean_error_km'] * group_stats['proportion']\n",
    "expected_total_error = group_stats['weighted_error'].sum()\n",
    "print(f\"\\nExpected Coordinate Error E[D]: {expected_total_error:.2f} km\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-Radius Accuracy Metrics:\n",
      "   <1 km: 0.49%\n",
      "   <5 km: 16.34%\n",
      "  <50 km: 64.62%\n",
      " <100 km: 70.02%\n",
      " <250 km: 78.13%\n",
      " <500 km: 82.80%\n",
      "<1000 km: 87.22%\n",
      "<5000 km: 94.23%\n"
     ]
    }
   ],
   "source": [
    "def compute_in_radius_metrics(y_true, y_pred, thresholds=[1, 5, 50, 100, 250, 500, 1000, 5000]):\n",
    "    \"\"\"\n",
    "    Compute % of predictions within given distance thresholds\n",
    "    y_true, y_pred: numpy arrays of shape (N, 2) for [lat, lon]\n",
    "    \"\"\"\n",
    "    distances = haversine_distance(\n",
    "        y_true[:, 0], y_true[:, 1], y_pred[:, 0], y_pred[:, 1]\n",
    "    )\n",
    "\n",
    "    results = {}\n",
    "    for r in thresholds:\n",
    "        percent = np.mean(distances <= r) * 100\n",
    "        results[f\"<{r} km\"] = percent\n",
    "    \n",
    "    return results, distances\n",
    "\n",
    "metrics, dists = compute_in_radius_metrics(y_test_coords, y_pred_coords)\n",
    "\n",
    "print(\"In-Radius Accuracy Metrics:\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k:>8}: {v:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_radius_by_group(df, group_col, thresholds=[1, 5, 50, 100, 250, 500, 1000, 5000]):\n",
    "    \"\"\"\n",
    "    Compute in-radius accuracy for a group column (continent, city, or continent+city)\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['coord_error'] = haversine_distance(\n",
    "        df['true_lat'].values, df['true_lon'].values,\n",
    "        df['pred_lat'].values, df['pred_lon'].values\n",
    "    )\n",
    "\n",
    "    results = {}\n",
    "    grouped = df.groupby(group_col)\n",
    "    \n",
    "    for group_name, group_df in grouped:\n",
    "        res = {}\n",
    "        errors = group_df['coord_error'].values\n",
    "        for r in thresholds:\n",
    "            res[f\"<{r} km\"] = np.mean(errors <= r) * 100  # in %\n",
    "        results[group_name] = res\n",
    "    \n",
    "    return pd.DataFrame(results).T  # Transpose for better readability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-Radius Accuracy per Continent\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&lt;1 km</th>\n",
       "      <th>&lt;5 km</th>\n",
       "      <th>&lt;50 km</th>\n",
       "      <th>&lt;100 km</th>\n",
       "      <th>&lt;250 km</th>\n",
       "      <th>&lt;500 km</th>\n",
       "      <th>&lt;1000 km</th>\n",
       "      <th>&lt;5000 km</th>\n",
       "      <th>continent_support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>east_asia</th>\n",
       "      <td>0.72</td>\n",
       "      <td>25.90</td>\n",
       "      <td>67.63</td>\n",
       "      <td>71.58</td>\n",
       "      <td>80.58</td>\n",
       "      <td>84.89</td>\n",
       "      <td>88.85</td>\n",
       "      <td>94.96</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>europe</th>\n",
       "      <td>0.71</td>\n",
       "      <td>20.14</td>\n",
       "      <td>63.96</td>\n",
       "      <td>71.38</td>\n",
       "      <td>77.74</td>\n",
       "      <td>81.98</td>\n",
       "      <td>87.63</td>\n",
       "      <td>93.99</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>middle_east</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>80.00</td>\n",
       "      <td>86.67</td>\n",
       "      <td>86.67</td>\n",
       "      <td>93.33</td>\n",
       "      <td>93.33</td>\n",
       "      <td>100.00</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>north_america</th>\n",
       "      <td>0.00</td>\n",
       "      <td>2.68</td>\n",
       "      <td>56.38</td>\n",
       "      <td>61.74</td>\n",
       "      <td>71.14</td>\n",
       "      <td>78.52</td>\n",
       "      <td>83.89</td>\n",
       "      <td>93.96</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oceania</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>22.22</td>\n",
       "      <td>22.22</td>\n",
       "      <td>22.22</td>\n",
       "      <td>44.44</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>south_america</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>47.62</td>\n",
       "      <td>52.38</td>\n",
       "      <td>71.43</td>\n",
       "      <td>80.95</td>\n",
       "      <td>85.71</td>\n",
       "      <td>90.48</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_saharan_africa</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>86.44</td>\n",
       "      <td>89.83</td>\n",
       "      <td>94.92</td>\n",
       "      <td>94.92</td>\n",
       "      <td>94.92</td>\n",
       "      <td>100.00</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    <1 km  <5 km  <50 km  <100 km  <250 km  <500 km  <1000 km  \\\n",
       "east_asia            0.72  25.90   67.63    71.58    80.58    84.89     88.85   \n",
       "europe               0.71  20.14   63.96    71.38    77.74    81.98     87.63   \n",
       "middle_east          0.00   0.00   80.00    86.67    86.67    93.33     93.33   \n",
       "north_america        0.00   2.68   56.38    61.74    71.14    78.52     83.89   \n",
       "oceania              0.00   0.00    0.00     0.00    22.22    22.22     22.22   \n",
       "south_america        0.00   0.00   47.62    52.38    71.43    80.95     85.71   \n",
       "sub_saharan_africa   0.00   0.00   86.44    89.83    94.92    94.92     94.92   \n",
       "\n",
       "                    <5000 km  continent_support  \n",
       "east_asia              94.96                278  \n",
       "europe                 93.99                283  \n",
       "middle_east           100.00                 15  \n",
       "north_america          93.96                149  \n",
       "oceania                44.44                  9  \n",
       "south_america          90.48                 21  \n",
       "sub_saharan_africa    100.00                 59  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continent_metrics = in_radius_by_group(df, group_col='true_cont_name')\n",
    "print(\"In-Radius Accuracy per Continent\")\n",
    "continent_metrics['continent_support'] = continent_metrics.index.map(cont_support_map)\n",
    "continent_metrics.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-Radius Accuracy per City\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&lt;1 km</th>\n",
       "      <th>&lt;5 km</th>\n",
       "      <th>&lt;50 km</th>\n",
       "      <th>&lt;100 km</th>\n",
       "      <th>&lt;250 km</th>\n",
       "      <th>&lt;500 km</th>\n",
       "      <th>&lt;1000 km</th>\n",
       "      <th>&lt;5000 km</th>\n",
       "      <th>city_support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>auckland</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baltimore</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>barcelona</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>berlin</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.67</td>\n",
       "      <td>40.00</td>\n",
       "      <td>86.67</td>\n",
       "      <td>93.33</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bogota</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>75.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brisbane</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>denver</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>60.00</td>\n",
       "      <td>73.33</td>\n",
       "      <td>86.67</td>\n",
       "      <td>86.67</td>\n",
       "      <td>93.33</td>\n",
       "      <td>100.00</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doha</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>80.00</td>\n",
       "      <td>86.67</td>\n",
       "      <td>86.67</td>\n",
       "      <td>93.33</td>\n",
       "      <td>93.33</td>\n",
       "      <td>100.00</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>europe</th>\n",
       "      <td>0.00</td>\n",
       "      <td>33.33</td>\n",
       "      <td>83.33</td>\n",
       "      <td>91.67</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fairbanks</th>\n",
       "      <td>0.00</td>\n",
       "      <td>14.29</td>\n",
       "      <td>38.10</td>\n",
       "      <td>42.86</td>\n",
       "      <td>57.14</td>\n",
       "      <td>61.90</td>\n",
       "      <td>61.90</td>\n",
       "      <td>76.19</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hamilton</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.33</td>\n",
       "      <td>33.33</td>\n",
       "      <td>33.33</td>\n",
       "      <td>66.67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hanoi</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>60.00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hong_kong</th>\n",
       "      <td>0.68</td>\n",
       "      <td>41.89</td>\n",
       "      <td>93.92</td>\n",
       "      <td>93.92</td>\n",
       "      <td>93.92</td>\n",
       "      <td>95.95</td>\n",
       "      <td>96.62</td>\n",
       "      <td>98.65</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ilorin</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>87.27</td>\n",
       "      <td>90.91</td>\n",
       "      <td>94.55</td>\n",
       "      <td>94.55</td>\n",
       "      <td>94.55</td>\n",
       "      <td>100.00</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kuala_lumpur</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>80.00</td>\n",
       "      <td>80.00</td>\n",
       "      <td>90.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kyiv</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>60.00</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lisbon</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.33</td>\n",
       "      <td>16.67</td>\n",
       "      <td>50.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>75.00</td>\n",
       "      <td>91.67</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>london</th>\n",
       "      <td>1.60</td>\n",
       "      <td>37.60</td>\n",
       "      <td>80.80</td>\n",
       "      <td>88.80</td>\n",
       "      <td>89.60</td>\n",
       "      <td>91.20</td>\n",
       "      <td>92.80</td>\n",
       "      <td>96.80</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marseille</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>80.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minneapolis</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naples</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.33</td>\n",
       "      <td>66.67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_york_city</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>63.81</td>\n",
       "      <td>67.62</td>\n",
       "      <td>76.19</td>\n",
       "      <td>84.76</td>\n",
       "      <td>90.48</td>\n",
       "      <td>97.14</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offa</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>75.00</td>\n",
       "      <td>75.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oslo</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>76.47</td>\n",
       "      <td>94.12</td>\n",
       "      <td>94.12</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paris</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rio_de_janeiro</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>57.14</td>\n",
       "      <td>71.43</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sacramento</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>san_francisco</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>santiago</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>80.00</td>\n",
       "      <td>80.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sao_paulo</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>60.00</td>\n",
       "      <td>80.00</td>\n",
       "      <td>80.00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sendai</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seoul</th>\n",
       "      <td>5.26</td>\n",
       "      <td>5.26</td>\n",
       "      <td>63.16</td>\n",
       "      <td>78.95</td>\n",
       "      <td>78.95</td>\n",
       "      <td>84.21</td>\n",
       "      <td>94.74</td>\n",
       "      <td>100.00</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>singapore</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.38</td>\n",
       "      <td>31.25</td>\n",
       "      <td>43.75</td>\n",
       "      <td>53.12</td>\n",
       "      <td>78.12</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sofia</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>66.67</td>\n",
       "      <td>100.00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stockholm</th>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>91.67</td>\n",
       "      <td>91.67</td>\n",
       "      <td>91.67</td>\n",
       "      <td>95.83</td>\n",
       "      <td>95.83</td>\n",
       "      <td>100.00</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>taipei</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>57.89</td>\n",
       "      <td>68.42</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokyo</th>\n",
       "      <td>0.00</td>\n",
       "      <td>23.68</td>\n",
       "      <td>68.42</td>\n",
       "      <td>73.68</td>\n",
       "      <td>81.58</td>\n",
       "      <td>86.84</td>\n",
       "      <td>89.47</td>\n",
       "      <td>92.11</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vienna</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yamaguchi</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zurich</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>42.11</td>\n",
       "      <td>47.37</td>\n",
       "      <td>57.89</td>\n",
       "      <td>57.89</td>\n",
       "      <td>63.16</td>\n",
       "      <td>84.21</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                <1 km  <5 km  <50 km  <100 km  <250 km  <500 km  <1000 km  \\\n",
       "auckland         0.00   0.00    0.00     0.00     0.00     0.00      0.00   \n",
       "baltimore        0.00   0.00    0.00     0.00     0.00     0.00      0.00   \n",
       "barcelona        0.00   0.00  100.00   100.00   100.00   100.00    100.00   \n",
       "berlin           0.00   0.00    6.67    40.00    86.67    93.33    100.00   \n",
       "bogota           0.00   0.00    0.00     0.00    25.00    50.00     50.00   \n",
       "brisbane         0.00   0.00    0.00     0.00    20.00    20.00     20.00   \n",
       "denver           0.00   0.00   60.00    73.33    86.67    86.67     93.33   \n",
       "doha             0.00   0.00   80.00    86.67    86.67    93.33     93.33   \n",
       "europe           0.00  33.33   83.33    91.67   100.00   100.00    100.00   \n",
       "fairbanks        0.00  14.29   38.10    42.86    57.14    61.90     61.90   \n",
       "hamilton         0.00   0.00    0.00     0.00    33.33    33.33     33.33   \n",
       "hanoi            0.00   0.00    0.00     0.00     0.00     0.00      0.00   \n",
       "hong_kong        0.68  41.89   93.92    93.92    93.92    95.95     96.62   \n",
       "ilorin           0.00   0.00   87.27    90.91    94.55    94.55     94.55   \n",
       "kuala_lumpur     0.00   0.00    0.00    10.00    80.00    80.00     90.00   \n",
       "kyiv             0.00   0.00   10.00    10.00    20.00    30.00     50.00   \n",
       "lisbon           0.00   0.00    8.33    16.67    50.00    50.00     75.00   \n",
       "london           1.60  37.60   80.80    88.80    89.60    91.20     92.80   \n",
       "marseille        0.00   0.00    0.00     0.00     0.00    80.00    100.00   \n",
       "minneapolis      0.00   0.00    0.00     0.00     0.00     0.00      0.00   \n",
       "naples           0.00   0.00    0.00     0.00     0.00     0.00     33.33   \n",
       "new_york_city    0.00   0.95   63.81    67.62    76.19    84.76     90.48   \n",
       "offa             0.00   0.00   75.00    75.00   100.00   100.00    100.00   \n",
       "oslo             0.00   0.00   76.47    94.12    94.12   100.00    100.00   \n",
       "paris            0.00   0.00    0.00     0.00   100.00   100.00    100.00   \n",
       "rio_de_janeiro   0.00   0.00   57.14    71.43   100.00   100.00    100.00   \n",
       "sacramento       0.00   0.00    0.00    50.00    50.00    50.00    100.00   \n",
       "san_francisco    0.00   0.00    0.00     0.00     0.00    50.00     50.00   \n",
       "santiago         0.00   0.00   80.00    80.00   100.00   100.00    100.00   \n",
       "sao_paulo        0.00   0.00   40.00    40.00    40.00    60.00     80.00   \n",
       "sendai           0.00   0.00    0.00     0.00    50.00   100.00    100.00   \n",
       "seoul            5.26   5.26   63.16    78.95    78.95    84.21     94.74   \n",
       "singapore        0.00   0.00    0.00     9.38    31.25    43.75     53.12   \n",
       "sofia            0.00   0.00    0.00     0.00     0.00     0.00     66.67   \n",
       "stockholm        0.00  25.00   91.67    91.67    91.67    95.83     95.83   \n",
       "taipei           0.00   0.00   57.89    68.42   100.00   100.00    100.00   \n",
       "tokyo            0.00  23.68   68.42    73.68    81.58    86.84     89.47   \n",
       "vienna           0.00   0.00    0.00     0.00     0.00    25.00     50.00   \n",
       "yamaguchi        0.00   0.00    0.00     0.00     0.00     0.00    100.00   \n",
       "zurich           0.00   0.00   42.11    47.37    57.89    57.89     63.16   \n",
       "\n",
       "                <5000 km  city_support  \n",
       "auckland          100.00             1  \n",
       "baltimore         100.00             1  \n",
       "barcelona         100.00            23  \n",
       "berlin            100.00            15  \n",
       "bogota             75.00             4  \n",
       "brisbane           20.00             5  \n",
       "denver            100.00            15  \n",
       "doha              100.00            15  \n",
       "europe            100.00            12  \n",
       "fairbanks          76.19            21  \n",
       "hamilton           66.67             3  \n",
       "hanoi              60.00             5  \n",
       "hong_kong          98.65           148  \n",
       "ilorin            100.00            55  \n",
       "kuala_lumpur      100.00            10  \n",
       "kyiv               60.00            20  \n",
       "lisbon             91.67            12  \n",
       "london             96.80           125  \n",
       "marseille         100.00             5  \n",
       "minneapolis       100.00             3  \n",
       "naples             66.67             3  \n",
       "new_york_city      97.14           105  \n",
       "offa              100.00             4  \n",
       "oslo              100.00            17  \n",
       "paris             100.00             1  \n",
       "rio_de_janeiro    100.00             7  \n",
       "sacramento        100.00             2  \n",
       "san_francisco      50.00             2  \n",
       "santiago          100.00             5  \n",
       "sao_paulo          80.00             5  \n",
       "sendai            100.00             4  \n",
       "seoul             100.00            19  \n",
       "singapore          78.12            32  \n",
       "sofia             100.00             3  \n",
       "stockholm         100.00            24  \n",
       "taipei            100.00            19  \n",
       "tokyo              92.11            38  \n",
       "vienna            100.00             4  \n",
       "yamaguchi         100.00             3  \n",
       "zurich             84.21            19  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_metrics = in_radius_by_group(df, group_col='true_city_name')\n",
    "print(\"In-Radius Accuracy per City\")\n",
    "city_metrics['city_support'] = city_metrics.index.map(city_support_map)\n",
    "city_metrics.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-Radius Accuracy per Continent-City\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&lt;1 km</th>\n",
       "      <th>&lt;5 km</th>\n",
       "      <th>&lt;50 km</th>\n",
       "      <th>&lt;100 km</th>\n",
       "      <th>&lt;250 km</th>\n",
       "      <th>&lt;500 km</th>\n",
       "      <th>&lt;1000 km</th>\n",
       "      <th>&lt;5000 km</th>\n",
       "      <th>continent_support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>east_asia / hanoi</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>60.00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>east_asia / hong_kong</th>\n",
       "      <td>0.68</td>\n",
       "      <td>41.89</td>\n",
       "      <td>93.92</td>\n",
       "      <td>93.92</td>\n",
       "      <td>93.92</td>\n",
       "      <td>95.95</td>\n",
       "      <td>96.62</td>\n",
       "      <td>98.65</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>east_asia / kuala_lumpur</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>80.00</td>\n",
       "      <td>80.00</td>\n",
       "      <td>90.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>east_asia / sendai</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>east_asia / seoul</th>\n",
       "      <td>5.26</td>\n",
       "      <td>5.26</td>\n",
       "      <td>63.16</td>\n",
       "      <td>78.95</td>\n",
       "      <td>78.95</td>\n",
       "      <td>84.21</td>\n",
       "      <td>94.74</td>\n",
       "      <td>100.00</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>east_asia / singapore</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.38</td>\n",
       "      <td>31.25</td>\n",
       "      <td>43.75</td>\n",
       "      <td>53.12</td>\n",
       "      <td>78.12</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>east_asia / taipei</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>57.89</td>\n",
       "      <td>68.42</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>east_asia / tokyo</th>\n",
       "      <td>0.00</td>\n",
       "      <td>23.68</td>\n",
       "      <td>68.42</td>\n",
       "      <td>73.68</td>\n",
       "      <td>81.58</td>\n",
       "      <td>86.84</td>\n",
       "      <td>89.47</td>\n",
       "      <td>92.11</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>east_asia / yamaguchi</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>europe / barcelona</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>europe / berlin</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.67</td>\n",
       "      <td>40.00</td>\n",
       "      <td>86.67</td>\n",
       "      <td>93.33</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>europe / europe</th>\n",
       "      <td>0.00</td>\n",
       "      <td>33.33</td>\n",
       "      <td>83.33</td>\n",
       "      <td>91.67</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>europe / kyiv</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>60.00</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>europe / lisbon</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.33</td>\n",
       "      <td>16.67</td>\n",
       "      <td>50.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>75.00</td>\n",
       "      <td>91.67</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>europe / london</th>\n",
       "      <td>1.60</td>\n",
       "      <td>37.60</td>\n",
       "      <td>80.80</td>\n",
       "      <td>88.80</td>\n",
       "      <td>89.60</td>\n",
       "      <td>91.20</td>\n",
       "      <td>92.80</td>\n",
       "      <td>96.80</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>europe / marseille</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>80.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>europe / naples</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.33</td>\n",
       "      <td>66.67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>europe / oslo</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>76.47</td>\n",
       "      <td>94.12</td>\n",
       "      <td>94.12</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>europe / paris</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>europe / sofia</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>66.67</td>\n",
       "      <td>100.00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>europe / stockholm</th>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>91.67</td>\n",
       "      <td>91.67</td>\n",
       "      <td>91.67</td>\n",
       "      <td>95.83</td>\n",
       "      <td>95.83</td>\n",
       "      <td>100.00</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>europe / vienna</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>europe / zurich</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>42.11</td>\n",
       "      <td>47.37</td>\n",
       "      <td>57.89</td>\n",
       "      <td>57.89</td>\n",
       "      <td>63.16</td>\n",
       "      <td>84.21</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>middle_east / doha</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>80.00</td>\n",
       "      <td>86.67</td>\n",
       "      <td>86.67</td>\n",
       "      <td>93.33</td>\n",
       "      <td>93.33</td>\n",
       "      <td>100.00</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>north_america / baltimore</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>north_america / denver</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>60.00</td>\n",
       "      <td>73.33</td>\n",
       "      <td>86.67</td>\n",
       "      <td>86.67</td>\n",
       "      <td>93.33</td>\n",
       "      <td>100.00</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>north_america / fairbanks</th>\n",
       "      <td>0.00</td>\n",
       "      <td>14.29</td>\n",
       "      <td>38.10</td>\n",
       "      <td>42.86</td>\n",
       "      <td>57.14</td>\n",
       "      <td>61.90</td>\n",
       "      <td>61.90</td>\n",
       "      <td>76.19</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>north_america / minneapolis</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>north_america / new_york_city</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>63.81</td>\n",
       "      <td>67.62</td>\n",
       "      <td>76.19</td>\n",
       "      <td>84.76</td>\n",
       "      <td>90.48</td>\n",
       "      <td>97.14</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>north_america / sacramento</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>north_america / san_francisco</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oceania / auckland</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oceania / brisbane</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oceania / hamilton</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.33</td>\n",
       "      <td>33.33</td>\n",
       "      <td>33.33</td>\n",
       "      <td>66.67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>south_america / bogota</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>75.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>south_america / rio_de_janeiro</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>57.14</td>\n",
       "      <td>71.43</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>south_america / santiago</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>80.00</td>\n",
       "      <td>80.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>south_america / sao_paulo</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>60.00</td>\n",
       "      <td>80.00</td>\n",
       "      <td>80.00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_saharan_africa / ilorin</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>87.27</td>\n",
       "      <td>90.91</td>\n",
       "      <td>94.55</td>\n",
       "      <td>94.55</td>\n",
       "      <td>94.55</td>\n",
       "      <td>100.00</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_saharan_africa / offa</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>75.00</td>\n",
       "      <td>75.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                <1 km  <5 km  <50 km  <100 km  <250 km  \\\n",
       "east_asia / hanoi                0.00   0.00    0.00     0.00     0.00   \n",
       "east_asia / hong_kong            0.68  41.89   93.92    93.92    93.92   \n",
       "east_asia / kuala_lumpur         0.00   0.00    0.00    10.00    80.00   \n",
       "east_asia / sendai               0.00   0.00    0.00     0.00    50.00   \n",
       "east_asia / seoul                5.26   5.26   63.16    78.95    78.95   \n",
       "east_asia / singapore            0.00   0.00    0.00     9.38    31.25   \n",
       "east_asia / taipei               0.00   0.00   57.89    68.42   100.00   \n",
       "east_asia / tokyo                0.00  23.68   68.42    73.68    81.58   \n",
       "east_asia / yamaguchi            0.00   0.00    0.00     0.00     0.00   \n",
       "europe / barcelona               0.00   0.00  100.00   100.00   100.00   \n",
       "europe / berlin                  0.00   0.00    6.67    40.00    86.67   \n",
       "europe / europe                  0.00  33.33   83.33    91.67   100.00   \n",
       "europe / kyiv                    0.00   0.00   10.00    10.00    20.00   \n",
       "europe / lisbon                  0.00   0.00    8.33    16.67    50.00   \n",
       "europe / london                  1.60  37.60   80.80    88.80    89.60   \n",
       "europe / marseille               0.00   0.00    0.00     0.00     0.00   \n",
       "europe / naples                  0.00   0.00    0.00     0.00     0.00   \n",
       "europe / oslo                    0.00   0.00   76.47    94.12    94.12   \n",
       "europe / paris                   0.00   0.00    0.00     0.00   100.00   \n",
       "europe / sofia                   0.00   0.00    0.00     0.00     0.00   \n",
       "europe / stockholm               0.00  25.00   91.67    91.67    91.67   \n",
       "europe / vienna                  0.00   0.00    0.00     0.00     0.00   \n",
       "europe / zurich                  0.00   0.00   42.11    47.37    57.89   \n",
       "middle_east / doha               0.00   0.00   80.00    86.67    86.67   \n",
       "north_america / baltimore        0.00   0.00    0.00     0.00     0.00   \n",
       "north_america / denver           0.00   0.00   60.00    73.33    86.67   \n",
       "north_america / fairbanks        0.00  14.29   38.10    42.86    57.14   \n",
       "north_america / minneapolis      0.00   0.00    0.00     0.00     0.00   \n",
       "north_america / new_york_city    0.00   0.95   63.81    67.62    76.19   \n",
       "north_america / sacramento       0.00   0.00    0.00    50.00    50.00   \n",
       "north_america / san_francisco    0.00   0.00    0.00     0.00     0.00   \n",
       "oceania / auckland               0.00   0.00    0.00     0.00     0.00   \n",
       "oceania / brisbane               0.00   0.00    0.00     0.00    20.00   \n",
       "oceania / hamilton               0.00   0.00    0.00     0.00    33.33   \n",
       "south_america / bogota           0.00   0.00    0.00     0.00    25.00   \n",
       "south_america / rio_de_janeiro   0.00   0.00   57.14    71.43   100.00   \n",
       "south_america / santiago         0.00   0.00   80.00    80.00   100.00   \n",
       "south_america / sao_paulo        0.00   0.00   40.00    40.00    40.00   \n",
       "sub_saharan_africa / ilorin      0.00   0.00   87.27    90.91    94.55   \n",
       "sub_saharan_africa / offa        0.00   0.00   75.00    75.00   100.00   \n",
       "\n",
       "                                <500 km  <1000 km  <5000 km  continent_support  \n",
       "east_asia / hanoi                  0.00      0.00     60.00                  5  \n",
       "east_asia / hong_kong             95.95     96.62     98.65                148  \n",
       "east_asia / kuala_lumpur          80.00     90.00    100.00                 10  \n",
       "east_asia / sendai               100.00    100.00    100.00                  4  \n",
       "east_asia / seoul                 84.21     94.74    100.00                 19  \n",
       "east_asia / singapore             43.75     53.12     78.12                 32  \n",
       "east_asia / taipei               100.00    100.00    100.00                 19  \n",
       "east_asia / tokyo                 86.84     89.47     92.11                 38  \n",
       "east_asia / yamaguchi              0.00    100.00    100.00                  3  \n",
       "europe / barcelona               100.00    100.00    100.00                 23  \n",
       "europe / berlin                   93.33    100.00    100.00                 15  \n",
       "europe / europe                  100.00    100.00    100.00                 12  \n",
       "europe / kyiv                     30.00     50.00     60.00                 20  \n",
       "europe / lisbon                   50.00     75.00     91.67                 12  \n",
       "europe / london                   91.20     92.80     96.80                125  \n",
       "europe / marseille                80.00    100.00    100.00                  5  \n",
       "europe / naples                    0.00     33.33     66.67                  3  \n",
       "europe / oslo                    100.00    100.00    100.00                 17  \n",
       "europe / paris                   100.00    100.00    100.00                  1  \n",
       "europe / sofia                     0.00     66.67    100.00                  3  \n",
       "europe / stockholm                95.83     95.83    100.00                 24  \n",
       "europe / vienna                   25.00     50.00    100.00                  4  \n",
       "europe / zurich                   57.89     63.16     84.21                 19  \n",
       "middle_east / doha                93.33     93.33    100.00                 15  \n",
       "north_america / baltimore          0.00      0.00    100.00                  1  \n",
       "north_america / denver            86.67     93.33    100.00                 15  \n",
       "north_america / fairbanks         61.90     61.90     76.19                 21  \n",
       "north_america / minneapolis        0.00      0.00    100.00                  3  \n",
       "north_america / new_york_city     84.76     90.48     97.14                105  \n",
       "north_america / sacramento        50.00    100.00    100.00                  2  \n",
       "north_america / san_francisco     50.00     50.00     50.00                  2  \n",
       "oceania / auckland                 0.00      0.00    100.00                  1  \n",
       "oceania / brisbane                20.00     20.00     20.00                  5  \n",
       "oceania / hamilton                33.33     33.33     66.67                  3  \n",
       "south_america / bogota            50.00     50.00     75.00                  4  \n",
       "south_america / rio_de_janeiro   100.00    100.00    100.00                  7  \n",
       "south_america / santiago         100.00    100.00    100.00                  5  \n",
       "south_america / sao_paulo         60.00     80.00     80.00                  5  \n",
       "sub_saharan_africa / ilorin       94.55     94.55    100.00                 55  \n",
       "sub_saharan_africa / offa        100.00    100.00    100.00                  4  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['continent_city'] = df['true_cont_name'] + \" / \" + df['true_city_name']\n",
    "cont_city_metrics = in_radius_by_group(df, group_col='continent_city')\n",
    "cont_city_metrics['continent_support'] = cont_city_metrics.index.map(lambda x :x.split(\"/\")[-1].strip()).map(city_support_map)\n",
    "print(\"In-Radius Accuracy per Continent-City\")\n",
    "cont_city_metrics.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "binp37_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
